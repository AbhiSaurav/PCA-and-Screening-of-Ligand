{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge xyz2mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "from numpy import sqrt \n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pylab\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.impute import SimpleImputer\n",
    "from statsmodels.multivariate.pca import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "df = pd.read_csv('/Users/abhisaurav/Desktop/comm_monophosphine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.iloc[:, 0:5], inplace=True, axis=1)\n",
    "df_X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_missing_values(df):\n",
    "    \"\"\" For each column with missing values plot proportion that is missing.\"\"\"\n",
    "    data = [(col, df[col].isnull().sum() / len(df)) \n",
    "            for col in df.columns if df[col].isnull().sum() > 0]\n",
    "    col_names = ['column', 'percent_missing']\n",
    "    missing_df = pd.DataFrame(data, columns=col_names).sort_values('percent_missing')\n",
    "    pylab.rcParams['figure.figsize'] = (15, 8)\n",
    "    missing_df.plot(kind='barh', x='column', y='percent_missing'); \n",
    "    plt.title('Percent of missing values in colummns');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_missing = df_X.isnull().sum()\n",
    "percent_missing = df_X.isnull().sum()/ len(df_X)\n",
    "missing_value_df = pd.DataFrame({'column_name': df_X.columns,\n",
    "                                 'count_missing': count_missing,\n",
    "                                 'percent_missing': percent_missing}\n",
    "\n",
    "missing_value_df = missing_value_df[missing_value_df['percent_missing']>0]\n",
    "missing_value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.multivariate.pca import PCA \n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import xlsxwriter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with correlation matrix of data - Nipals\n",
    "\n",
    "pc1 = PCA(df_X,\n",
    "         ncomp=4,\n",
    "         standardize=True,\n",
    "         demean=True,\n",
    "         normalize=False,\n",
    "         gls=False,\n",
    "         weights=None,\n",
    "         method='nipals', \n",
    "         missing='fill-em')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pc1.loadings.T\n",
    "df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_factors = pc1.factors\n",
    "X1_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = X1_factors.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X1_factors.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with covariance matrix of data - Nipals\n",
    "\n",
    "pc2 = PCA(df_X,\n",
    "         ncomp=4,\n",
    "         standardize=False,\n",
    "         demean=True,\n",
    "         normalize=False,\n",
    "         gls=False,\n",
    "         weights=None,\n",
    "         method='nipals',\n",
    "         missing='fill-em')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pc2.loadings.T\n",
    "df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_factors = pc2.factors\n",
    "X2_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = X2_factors.corr()\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X2_factors.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.multivariate.factor import Factor\n",
    "model = Factor(X2_factors).fit()\n",
    "model.plot_scree()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance=pc1.eigenvals\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = explained_variance/np.sum(explained_variance)\n",
    "explained_variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sns\n",
    " .lineplot(x=np.arange(1, 5),\n",
    "           y=explained_variance_ratio,\n",
    "           marker=\"o\")\n",
    " .set(title=\"PVE vs. Principal Component\",\n",
    "      xlabel=\"Principal Component\",\n",
    "      ylabel=\"Proportion of Variance Explained\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative PVE vs. Principal Component plot\n",
    "(sns\n",
    " .lineplot(x=np.arange(1, 5),\n",
    "           y=np.cumsum(explained_variance_ratio),\n",
    "           marker=\"o\")\n",
    " .set(title=\"Cumulative PVE vs. Principal Component\",\n",
    "      xlabel=\"Principal Component\",\n",
    "      ylabel=\"Cumulative Proportion of Variance Explained\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with plt.style.context('dark_background'):\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.bar(range(4), explained_variance_ratio, alpha=0.5, align='center',label='individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono = pd.read_csv('/Users/abhisaurav/Desktop/comm_monophosphine.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_pca=mono.join(X2_factors)\n",
    "mono_comm = mono_pca[mono_pca['com']==1]\n",
    "#mono_comm=mono_comm.assign(size=lambda x: abs(x.comp_0))\n",
    "mono_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# For plotting with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# For plotting with seaborn\n",
    "import seaborn as sns  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_discrete = {\"N\": 'green', \"Y\": 'red'}\n",
    "\n",
    "fig = px.scatter_3d(mono_comm, x='comp_0', y='comp_1', z='comp_2',\n",
    "                    color = 'symbol',\n",
    "                    color_discrete_map=color_discrete,\n",
    "                    text = 'check',\n",
    "                    hover_name = 'Kraken ID',\n",
    "                    size = 'vbur_vbur_min',\n",
    "                    size_max=30)\n",
    "#fig.show()\n",
    "fig.update_layout(margin=dict(l=10, r=10, b=10, t=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_cluster=df_X.join(X2_factors)\n",
    "mono_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This normalization will be performed just for PC1 and PC2, but can be done for all the components.\n",
    "scale1 = 1.0/(max(mono_cluster['comp_0']) - min(mono_cluster['comp_0']))\n",
    "scale2 = 1.0/(max(mono_cluster['comp_1']) - min(mono_cluster['comp_1']))\n",
    "scale3 = 1.0/(max(mono_cluster['comp_2']) - min(mono_cluster['comp_2']))\n",
    "scale4 = 1.0/(max(mono_cluster['comp_3']) - min(mono_cluster['comp_3']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And we add the new values to our PCA table\n",
    "mono_cluster['PC0_normalized']=[i*scale1 for i in mono_cluster['comp_0']]\n",
    "mono_cluster['PC1_normalized']=[i*scale2 for i in mono_cluster['comp_1']]\n",
    "mono_cluster['PC2_normalized']=[i*scale3 for i in mono_cluster['comp_2']]\n",
    "mono_cluster['PC3_normalized']=[i*scale4 for i in mono_cluster['comp_3']]\n",
    "mono_cluster.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "wcss = []\n",
    "for i in range(1,11):\n",
    "   model = KMeans(n_clusters = i, init = \"k-means++\")\n",
    "   model.fit(mono_cluster)\n",
    "   wcss.append(model.inertia_)\n",
    "plt.plot(range(1,11), wcss)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference : https://chem-workflows.com/articles/2019/07/02/exploring-the-chemical-space-by-pca/\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "range_n_clusters = [2, 3, 4, 5, 6]\n",
    "for n_clusters in range_n_clusters:\n",
    "    fig, (ax1,ax2)= plt.subplots(1, 2)\n",
    "    fig.set_size_inches(8, 4)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = kmeans.fit_predict(mono_cluster[['PC0_normalized','PC1_normalized','PC2_normalized','PC3_normalized']])\n",
    "    silhouette_avg = silhouette_score(mono_cluster[['PC0_normalized','PC1_normalized','PC2_normalized','PC3_normalized']], cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    sample_silhouette_values = silhouette_samples(mono_cluster[['PC0_normalized','PC1_normalized','PC2_normalized','PC3_normalized']], cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(mono_cluster['PC1_normalized'], mono_cluster['PC2_normalized'], \n",
    "                marker='.', s=30, lw=0, alpha=0.7,c=colors, edgecolor='k')\n",
    "\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = kmeans.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"PC1\")\n",
    "    ax2.set_ylabel(\"PC2\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=10) # We define the best number of clusters\n",
    "clusters = kmeans.fit(mono_cluster[['PC0_normalized','PC1_normalized','PC2_normalized','PC3_normalized']]) #PC1 vs PC2 (normalized values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_cluster['Cluster'] = pd.Series(clusters.labels_, index=df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_pca['Cluster'] = pd.Series(clusters.labels_, index=mono_pca.index)\n",
    "mono_comm = mono_pca[mono_pca['com']==1]\n",
    "#mono_comm['viz'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mono_comm.loc[mono_comm['symbol'] == 'Y', 'viz'] = 'ligand'\n",
    "mono_comm.loc[mono_comm['symbol'] == 'N', 'viz'] = mono_comm['Cluster']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_discrete = {\"ligand\": 'red', 0: 'blue', 1: 'green'}\n",
    "\n",
    "fig = px.scatter_3d(mono_comm, x='comp_0', y='comp_1', z='comp_2',\n",
    "                    color = 'viz',\n",
    "                    #symbol = 'symbol',\n",
    "                    color_discrete_map=color_discrete,\n",
    "                    text = 'check',\n",
    "                    hover_name = 'Kraken ID',\n",
    "                    size = 'vbur_vbur_min',\n",
    "                    size_max=30)\n",
    "#fig.show()\n",
    "fig.update_layout(margin=dict(l=10, r=10, b=10, t=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model. Alpha is the threshold for the hotellings T2 test to determine outliers in the data.\n",
    "model = pca(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.fit_transform(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = out['explained_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exv = out['variance_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out['outliers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sns\n",
    " .lineplot(x=np.arange(1, 5),\n",
    "           y=np.cumsum(exv),\n",
    "           marker=\"o\")\n",
    " .set(title=\"Cumulative PVE vs. Principal Component\",\n",
    "      xlabel=\"Principal Component\",\n",
    "      ylabel=\"Cumulative Proportion of Variance Explained\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with plt.style.context('dark_background'):\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.bar(range(4), exv, alpha=0.5, align='center', label='individual explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier = pd.DataFrame.from_dict(out['outliers'])\n",
    "outlier.to_excel('/Users/abhisaurav/Desktop/outliers.xlsx', sheet_name='outliers', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.biplot(SPE=True,hotellingt2=True,label=None)\n",
    "model.scatter(SPE=True,hotellingt2=True,label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make biplot\n",
    "model.biplot(label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install rdkit\n",
    "#!pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap,LinearSegmentedColormap\n",
    "from sklearn.cluster import KMeans\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem,Geometry\n",
    "from rdkit.Chem import rdmolfiles, AllChem, rdMolAlign,rdmolops, Descriptors, Draw, PandasTools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jupyter_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only necessary for the interactive dashboards \n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output, State, no_update\n",
    "import plotly.graph_objects as go\n",
    "from jupyter_dash import JupyterDash\n",
    "\n",
    "colors32 = ['#000000', '#222034', '#45283c', '#663931', '#8f563b', '#df7126', \n",
    "            '#d9a066', '#eec39a', '#fbf236', '#99e550', '#6abe30', '#37946e', \n",
    "            '#4b692f', '#524b24', '#323c39', '#3f3f74', '#306082', '#5b6ee1', \n",
    "            '#639bff', '#5fcde4', '#cbdbfc', '#dddddd', '#9badb7', '#847e87', \n",
    "            '#696a6a', '#595652', '#76428a', '#ac3232', '#d95763', '#d77bba', \n",
    "            '#8f974a', '#8a6f30']\n",
    "\n",
    "def mol_to_img_df(row):\n",
    "    mol = Chem.MolFromSmiles(row[\"smiles\"])\n",
    "    return(Draw.MolToImage(mol))\n",
    "\n",
    "def dist_to_center(line):\n",
    "    delta = line[use_cols] - kmeans.cluster_centers_[line[\"cluster\"]]\n",
    "    dist = np.linalg.norm(delta)\n",
    "    return(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('/Users/abhisaurav/Desktop/comm_monophosphine_dash.csv')\n",
    "\n",
    "print(\"Features\")\n",
    "print(features.shape)\n",
    "display(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = pd.read_csv('/Users/abhisaurav/Desktop/comm_monophosphine_dash.csv')\n",
    "\n",
    "print(\"Filters\")\n",
    "print(filters.shape)\n",
    "display(filters.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_rows = features.index \n",
    "criterion1 = set(filters.loc[filters[\"com\"] == 1].index)\n",
    "criterion2 = set(filters.loc[filters[\"com\"] == 1].index)\n",
    "use_rows = sorted(criterion1 & criterion2)                \n",
    "print(f\"Keeping {len(use_rows)} compounds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclusters = 32\n",
    "use_space = \"PCA\"\n",
    "\n",
    "find_cols = {\"PCA\": [\"PC0_normalized\",\"PC1_normalized\",\"PC2_normalized\",\"PC3_normalized\"]}\n",
    "\n",
    "use_cols = find_cols[use_space]\n",
    "X_kmeans = features.loc[use_rows,use_cols]\n",
    "\n",
    "kmeans = KMeans(n_clusters=nclusters, random_state=1).fit(X_kmeans)\n",
    "data_df = features.loc[use_rows].copy()\n",
    "\n",
    "data_df[\"closest_to_center\"] = 0\n",
    "data_df[\"cluster\"] = kmeans.labels_\n",
    "data_df[\"distance_to_center\"] = data_df.apply(dist_to_center, axis = 1)\n",
    "clustermins = []\n",
    "for clusternumber in range(nclusters):\n",
    "    min_to_center_idx = data_df[data_df[\"cluster\"] == clusternumber][\"distance_to_center\"].idxmin()\n",
    "    clustermins.append(min_to_center_idx)\n",
    "    data_df.loc[min_to_center_idx,\"closest_to_center\"] = 1\n",
    "\n",
    "clustercounts = Counter(data_df[\"cluster\"])\n",
    "print(\"cluster: N(samples)\")\n",
    "for i in sorted(clustercounts.keys()):\n",
    "    print(f\"{i}: {clustercounts[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.cluster = data_df.cluster.astype(str)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation and Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molobs = [Chem.MolFromSmiles(i) for i in data_df.loc[clustermins][\"smiles\"]]\n",
    "legends = [f\"Cluster: {k}, ID: {v}\" for k,v in enumerate(clustermins)]\n",
    "img_src = Draw.MolsToGridImage(molobs, subImgSize=(225,250), molsPerRow=4,\n",
    "                                  legends = legends)\n",
    "Draw.MolsToGridImage(molobs, subImgSize=(225,250), molsPerRow=5,\n",
    "                                  legends = legends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "# For plotting with matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# For plotting with seaborn\n",
    "import seaborn as sns  \n",
    "\n",
    "color_discrete = {\"N\": 'green', \"Y\": 'red'}\n",
    "\n",
    "fig = px.scatter_3d(data_df, x='comp_0', y='comp_1', z='comp_2',\n",
    "                    color = 'cluster',\n",
    "                    #symbol = 'symbol',\n",
    "                    color_discrete_map=color_discrete,\n",
    "                    text = 'check',\n",
    "                    size_max=30,\n",
    "                   opacity=0.8)\n",
    "#fig.show()\n",
    "fig.update_layout(margin=dict(l=10, r=10, b=10, t=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: Dr. Tobias Gensch, 2022\n",
    "#Gensch, T.; Smith, S.; Colacot, T.; Timsina, Y.; Xu, G.; Glasspoole, B.; Sigman, \n",
    "#M. Design and Application of a Screening Set for Monophosphine Ligands in Metal Catalysis\n",
    "\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "app.layout = html.Div([  \n",
    "    html.Div(\"Select cluster:\"),\n",
    "    html.Div(\n",
    "        dcc.RadioItems(\n",
    "            id = 'clusters_select',\n",
    "            options = [{'value': x, 'label': x}\n",
    "            for x in range(nclusters)],\n",
    "            value = 0,\n",
    "            labelStyle={\"display\": \"inline-block\"},\n",
    "    ),\n",
    "        style = {\"width\": \"60%\", \"display\":\"inline-block\"}\n",
    "    ),\n",
    "    \n",
    "    html.P(),\n",
    "    \n",
    "    html.Div([\"Show up to N molecules nearest to the cluster center: \",\n",
    "        dcc.Input(\n",
    "            id = \"show_n_mols\", type = \"number\", value = 4, min = 1, step = 1,\n",
    "            style={\"width\":\"5%\"}\n",
    "        )\n",
    "    ]),\n",
    "    \n",
    "    html.Img(id=\"molecules_img\"),\n",
    "])\n",
    "\n",
    "@app.callback(Output(\"molecules_img\", \"src\"),[Input(\"show_n_mols\",\"value\"),Input(\"clusters_select\",\"value\")])\n",
    "\n",
    "def generate_molimg(show_n_mols,clusters_select):\n",
    "    show_n_mols = int(show_n_mols)\n",
    "    clustermin_idx = clustermins[clusters_select]\n",
    "    \n",
    "    sorted_mols = data_df.loc[data_df[\"cluster\"] == clusters_select].sort_values(by=\"distance_to_center\")\n",
    "    showno = min(show_n_mols,len(sorted_mols))\n",
    "    show_idxs = sorted_mols.iloc[:showno].index\n",
    "    molobs = [Chem.MolFromSmiles(i) for i in sorted_mols.loc[show_idxs,\"smiles\"]]\n",
    "    legends = [f\"ID: {i}, Dist: {data_df.loc[i,'distance_to_center']:.2f}\" for i in show_idxs]\n",
    "    img_src = Draw.MolsToGridImage(molobs, subImgSize=(125,150), molsPerRow=3,legends = legends)\n",
    "    \n",
    "    return(img_src)\n",
    "\n",
    "#app.run_server(mode='inline', port = 3689)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
